<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Travis Green</title>
    <link>https://greent3.github.io/tags/python/</link>
    <description>Recent content in Python on Travis Green</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="https://greent3.github.io/tags/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>B. Django E-Learning Platform</title>
      <link>https://greent3.github.io/projects/creations/2_e-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://greent3.github.io/projects/creations/2_e-learning/</guid>
      <description>Back-end of an online learning platform built using Python Django
Some features of the project:
A content management system (CMS) model inheritance class based views and mixins formsets and model formsets groups and permissions dynamic content caching (Memcache &amp;amp; redis) A callable RESTful API to interact with course data This project was completed as a tutorial outlined in Packt&amp;rsquo;s Django 4 By Example, and is not my original work</description>
    </item>
    
    <item>
      <title>C. TensorFlow Road Sign Classifier</title>
      <link>https://greent3.github.io/projects/creations/3_road_sign_classifier/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://greent3.github.io/projects/creations/3_road_sign_classifier/</guid>
      <description>As research continues in the development of self-driving cars, one of the key challenges is allowing these cars to develop an understanding of their environment from digital images.
In my traffic-sign classification project, I used TensorFlow and the German Traffic Sign Recognition Benchmark dataset to build a neural network that puts images of road signs into different classifications.
My role consisted of loading the data (images) into the program, resizing the images, and designing/implementing the neural network.</description>
    </item>
    
    <item>
      <title>D. RESTful Movie Database API w/ extensive unit testing</title>
      <link>https://greent3.github.io/projects/creations/4_restful-imdb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://greent3.github.io/projects/creations/4_restful-imdb/</guid>
      <description>The project is divided into 2 apps. Movielist app: handles all movie database functionality (adding movies to the database, querying lists of movies, creating/viewing reviews, etc.) along with their associated permissions. User app: handles user functionality (login, register, etc.) The unit testing covers all intented functionality for each level of authentication. The project also employs validators, pagination, and throttling.</description>
    </item>
    
    <item>
      <title>G. Ecommerce Purchase Predictor</title>
      <link>https://greent3.github.io/projects/creations/7_knn_purchase_predictor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://greent3.github.io/projects/creations/7_knn_purchase_predictor/</guid>
      <description>When we run our program, we pass the location of a CSV file containing data about website shoppers as a command line argument. Our program:
loads in that data reformats it into the correct data type splits it into training and testing data uses that data to train a k-nearest neighbors classification model and outputs the sensitivity (true positive rate) and specificity (true negative rate) of our trained model on our testing data.</description>
    </item>
    
    <item>
      <title>H. Whisky Review Sentiment Classifier</title>
      <link>https://greent3.github.io/projects/creations/8_naive_bayes_review_classifier/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://greent3.github.io/projects/creations/8_naive_bayes_review_classifier/</guid>
      <description>Classifying Japanese Whisky reviews using TFIDF/Naive Bayes
Given a CSV file with 200 Japanese whisky reviews labeled &amp;ldquo;positive&amp;rdquo; or &amp;ldquo;negative&amp;rdquo;, and 900 unlabeled reviews, let&amp;rsquo;s train a Naive Bayes model on TFIDF data so we can predict the labels for the remaining 900.
Note: The dataset was not that great (small, lots of typos, many negative reviews with positive sentiment words &amp;ldquo;ex: not that good&amp;rdquo;), but it still served as good practice for cleaning data, NB, vectorizers, working with dataframes, and even a little bit of SQL at the end.</description>
    </item>
    
    <item>
      <title>I. Car Price Predictor</title>
      <link>https://greent3.github.io/projects/creations/9_car_price_predictor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://greent3.github.io/projects/creations/9_car_price_predictor/</guid>
      <description></description>
    </item>
    
    <item>
      <title>J. Golden Cross Trading Algo (video)</title>
      <link>https://greent3.github.io/projects/creations/93_golden_cross/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://greent3.github.io/projects/creations/93_golden_cross/</guid>
      <description>Buys or sells an equity in anticipation of the 5 period SMA crossing the 20 period SMA and employs a trailing stoploss. Resolution, SMA periods, stoplosses, and order entry/exit points are all optimizable.
Video linked below!</description>
    </item>
    
    <item>
      <title>L. Detective Conan Web Scraper</title>
      <link>https://greent3.github.io/projects/creations/95_scraping_detective_conan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://greent3.github.io/projects/creations/95_scraping_detective_conan/</guid>
      <description>Yay! We convinced our buddy (Doug) to watch Detective Conan! However, he already read the manga and doesn&amp;rsquo;t want to watch episodes that he&amp;rsquo;s already read. No worries! Let&amp;rsquo;s use the data at Detective Conan Wiki to compile a list of episodes that weren&amp;rsquo;t in the manga.</description>
    </item>
    
    <item>
      <title>M. Teaching a robot NIM</title>
      <link>https://greent3.github.io/projects/creations/96_nim_bot/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://greent3.github.io/projects/creations/96_nim_bot/</guid>
      <description>By playing against itself repeatedly and learning from experience, eventually our AI will learn which actions to take and which actions to avoid when playing Nim. We do this through Q-learning, or assigning a reward value for every (state, action) pair. Weâ€™ll represent the game as an array (game board) of numbers (# of pieces in each row).</description>
    </item>
    
    <item>
      <title>P. TicTacToe AI</title>
      <link>https://greent3.github.io/projects/creations/991_tic_tac_toe/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://greent3.github.io/projects/creations/991_tic_tac_toe/</guid>
      <description>TicTacToe AI that uses a recursive minimax algorithm to determine the best possible move to make based on the best possible move their opponent (me) can play on the next turn.
Our algorithm also keeps track of who&amp;rsquo;s turn it is, all possible moves given the current state of the board, and whether or not someone has won the game.
Completed as part of Harvard&amp;rsquo;s AI with programming course.</description>
    </item>
    
    <item>
      <title>Q. Minesweeper AI</title>
      <link>https://greent3.github.io/projects/creations/992_minesweeper/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://greent3.github.io/projects/creations/992_minesweeper/</guid>
      <description>An AI capable of successfully finishing a game of minesweeper
Logic is stored in the form of sentences, and the program uses a recursive algorithm to make inferences based on new knowledge obtained by clicking unexplored cells.
The bot does not always win as sometimes there are no safe cells to click, and at that point the bot will have to make a random move.
Completed as part of Harvard&amp;rsquo;s AI programming with python course.</description>
    </item>
    
    <item>
      <title>R. Constraint Satisfication Crossword Solver</title>
      <link>https://greent3.github.io/projects/creations/993_ai_crossword_constraint/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://greent3.github.io/projects/creations/993_ai_crossword_constraint/</guid>
      <description>Brute force solving a crossword puzzle with unary constraints (length of words) and binary constraints (overlapping letters between words).
The AI uses domains to manage possible words that can be used in the puzzle. When the program reaches a point where a constraint is no longer satisfied, it backtracks and removes unusable words from the domain.
Completed as part of Harvard&amp;rsquo;s AI programming with Python course.</description>
    </item>
    
  </channel>
</rss>
